{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tokens', 'Intent', 'ner_labels'],\n",
       "        num_rows: 2245\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Tokens', 'Intent', 'ner_labels'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset = load_dataset('json', data_files='data/train_data.json')\n",
    "model_checkpoint = 'VietAI/vit5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, max_length=256)\n",
    "\n",
    "train_size = int(0.9 * len(dataset['train']))\n",
    "dataset['train'].shuffle()\n",
    "train_dataset = dataset['train'].select(range(train_size))\n",
    "val_dataset = dataset['train'].select(range(train_size, len(dataset['train'])))\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19, 20, 20, 20, 0, 5, 6, 0, 0, 3, 4, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 19, 20, 20, 20, 0, 5, 6, 0, 0, 3, 4, 0, 0, 0, 0, 1, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "all_labels = ['O', 'B-balcony_direction','I-balcony_direction','B-city','I-city','B-district','I-district','B-house_direction','I-house_direction', 'B-legal','I-legal', 'B-max_acreage','I-max_acreage', 'B-max_price','I-max_price','B-min_acreage','I-min_acreage','B-min_price','I-min_price', 'B-type_of_land','I-type_of_land']\n",
    "\n",
    "def create_ner_tags(examples):\n",
    "    \n",
    "    ner_tags = [[all_labels.index(label) for label in labels] for labels in examples[\"ner_labels\"]]\n",
    "\n",
    "    return {\"ner_tags\": ner_tags}\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "raw_datasets = raw_datasets.map(create_ner_tags, batched=True)\n",
    "\n",
    "labels = raw_datasets[\"train\"][45][\"ner_tags\"]\n",
    "inputs = tokenizer(raw_datasets[\"train\"][45][\"Tokens\"], is_split_into_words=True)\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f0d183d5ea434d8d97dea7479a1f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2245\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"Tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    3,    4,    0,    7,    0,    0,   17,\n",
       "           18,    0,   13,   14, -100],\n",
       "        [  19,   20,    0,    0,    0,    3,    4,    0,    7,    0,    0,    9,\n",
       "           10,   10,    0, -100, -100]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at VietAI/vit5-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(all_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = [[all_labels[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebd622fe5b04d61be5b86f205e85f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc41ef1e7a544361bd0bd2fc7404810d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lg\\miniconda3\\envs\\tova\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4586713910102844, 'eval_precision': 0.9241573033707865, 'eval_recall': 0.996969696969697, 'eval_f1': 0.9591836734693877, 'eval_accuracy': 0.9877712031558186, 'eval_runtime': 3.6307, 'eval_samples_per_second': 68.858, 'eval_steps_per_second': 8.814, 'epoch': 1.0}\n",
      "{'loss': 1.568, 'grad_norm': 24.983171463012695, 'learning_rate': 8.137603795966786e-06, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eac355f72ec4f99a61dbbf62fc71973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lg\\miniconda3\\envs\\tova\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5133143663406372, 'eval_precision': 0.9189944134078212, 'eval_recall': 0.996969696969697, 'eval_f1': 0.9563953488372093, 'eval_accuracy': 0.9881656804733728, 'eval_runtime': 3.4152, 'eval_samples_per_second': 73.202, 'eval_steps_per_second': 9.37, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b120d472ff46359a4b3da2c94e282d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lg\\miniconda3\\envs\\tova\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4648110568523407, 'eval_precision': 0.9189944134078212, 'eval_recall': 0.996969696969697, 'eval_f1': 0.9563953488372093, 'eval_accuracy': 0.9877712031558186, 'eval_runtime': 3.6696, 'eval_samples_per_second': 68.127, 'eval_steps_per_second': 8.72, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1051.1203, 'train_samples_per_second': 6.407, 'train_steps_per_second': 0.802, 'train_loss': 0.933494241495008, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=843, training_loss=0.933494241495008, metrics={'train_runtime': 1051.1203, 'train_samples_per_second': 6.407, 'train_steps_per_second': 0.802, 'total_flos': 90513448126200.0, 'train_loss': 0.933494241495008, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"ViT5-real-estate-ner\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'city',\n",
       "  'score': 1.0,\n",
       "  'word': 'Hùng',\n",
       "  'start': 10,\n",
       "  'end': 15}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_checkpoint = \"ViT5-real-estate-ner\"\n",
    "\n",
    "ner = pipeline(\"ner\", model=model_checkpoint, aggregation_strategy=\"simple\", device=0)\n",
    "ner(\"Tôi tên là Hùng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://ysharma-llama3-2-with-gradio-5.hf.space ✔\n",
      "content='Để tìm kiếm thông tin về các căn nhà ở quận 1 có giá dưới 1 tỷ đồng, bạn có thể sử dụng câu lệnh sau:\\n\\n[CALL_TOOL_QUERY_REAL_ESTATE \"quận 1\" \"dưới 1 tỷ\"]\\n\\nHoặc nếu bạn muốn yêu cầu cụ thể hơn là tìm kiếm căn nhà trong khu vực trung tâm hoặc gần các điểm du lịch nổi tiếng, bạn có thể thêm một số thông tin khác vào câu lệnh.\\n\\nVí dụ:\\n[CALL_TOOL_QUERY_REAL_ESTATE \"quận 1\" \"dưới 1 tỷ\" \"trung tâm\"]\\nhoặc \\n[CALL_TOOL_QUERY_REAL_ESTATE \"quận 1\" \"dưới 1 tỷ\" \"gần Bến Thành\"]' id='run-46ea4077-5a38-4efd-9eea-a559d83663ad-0'\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.outputs import ChatGeneration, ChatResult\n",
    "from typing import Any, List, Optional, Dict\n",
    "from gradio_client import Client\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "\n",
    "\n",
    "class LLama_3(BaseChatModel):\n",
    "    \"\"\"A custom chat model that echoes the first `n` characters of the input.\n",
    "\n",
    "    When contributing an implementation to LangChain, carefully document\n",
    "    the model including the initialization parameters, include\n",
    "    an example of how to initialize the model and include any relevant\n",
    "    links to the underlying models documentation or API.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            model = CustomChatModel(n=2)\n",
    "            result = model.invoke([HumanMessage(content=\"hello\")])\n",
    "            result = model.batch([[HumanMessage(content=\"hello\")],\n",
    "                                 [HumanMessage(content=\"world\")]])\n",
    "    \"\"\"\n",
    "\n",
    "    client: Client\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"Override the _generate method to implement the chat model logic.\n",
    "\n",
    "        This can be a call to an API, a call to a local model, or any other\n",
    "        implementation that generates a response to the input prompt.\n",
    "\n",
    "        Args:\n",
    "            messages: the prompt composed of a list of messages.\n",
    "            stop: a list of strings on which the model should stop generating.\n",
    "                  If generation stops due to a stop token, the stop token itself\n",
    "                  SHOULD BE INCLUDED as part of the output. This is not enforced\n",
    "                  across models right now, but it's a good practice to follow since\n",
    "                  it makes it much easier to parse the output of the model\n",
    "                  downstream and understand why generation stopped.\n",
    "            run_manager: A run manager with callbacks for the LLM.\n",
    "        \"\"\"\n",
    "        latest_message = messages[-1].content\n",
    "        \n",
    "        chat_history = []\n",
    "        for message in messages[:-1]:\n",
    "            chat_history.append({\"role\": \"user\", \"metadata\": {\"title\": None}, \"content\": message.content})\n",
    "\n",
    "        result = self.client.predict(\n",
    "            message=latest_message,\n",
    "            chat_history=chat_history,\n",
    "            max_new_tokens=1024,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.2,\n",
    "            api_name=\"/generate\"\n",
    "        )\n",
    "        message = AIMessage(content=result[1][-1]['content'])\n",
    "        generation = ChatGeneration(message=message)\n",
    "        return ChatResult(generations=[generation])\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Get the type of language model used by this chat model.\"\"\"\n",
    "        return \"llama\"\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return a dictionary of identifying parameters.\n",
    "\n",
    "        This information is used by the LangChain callback system, which\n",
    "        is used for tracing purposes make it possible to monitor LLMs.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            # The model name allows users to specify custom token counting\n",
    "            # rules in LLM monitoring applications (e.g., in LangSmith users\n",
    "            # can provide per token pricing for their model and monitor\n",
    "            # costs for the given LLM.)\n",
    "            \"model_name\": \"llama-3.2-instruct-3b\"\n",
    "        }\n",
    "    \n",
    "client = Client(\"ysharma/Llama3-2_with_Gradio-5\")\n",
    "custom_llm = LLama_3(client=client)\n",
    "\n",
    "chat_history = [\n",
    "    # HumanMessage(content=\"Hello!!\"),\n",
    "    # AIMessage(content=\"It's nice to meet you. Is there something I can help you with or would you like to chat?\"),\n",
    "    HumanMessage(content=\"what is the multiplication of 2 and 3?\"),\n",
    "]\n",
    "result = custom_llm.invoke(chat_history)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi đã ghi nhận yêu cầu của bạn về thông tin chung cư mini ở Hồ Chí Minh. Tuy nhiên, để cung cấp thông tin chính xác và phù hợp nhất, tôi cần một số thông tin thêm:\n",
      "\n",
      "1. **Vị trí cụ thể**: Bạn quan tâm đến khu vực nào ở Hồ Chí Minh?\n",
      "2. **Số phòng**: Bạn cần bao nhiêu phòng ngủ?\n",
      "3. **Giá cả**: Bạn có ngân sách cụ thể không?\n",
      "4. **Tiện ích**: Bạn có yêu cầu đặc biệt về tiện ích như an ninh, gym, hồ bơi, v.v.?\n",
      "\n",
      "Vui lòng cung cấp thêm thông tin để tôi có thể hỗ trợ bạn tốt hơn.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "client = InferenceClient(api_key=os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "messages = [\n",
    "\t{ \"role\": \"system\", \"content\": \"Bạn là một trợ lý ảo. Nếu người dùng hỏi những câu liên quan đến bất động sản, tìm nhà, hãy trả lời \\\"[CALL_TOOL]\\\". Còn lại thì trả lời như bình thường\" },\n",
    "\t{ \"role\": \"user\", \"content\": \"Xin chào\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"Xin chào! Rất vui được gặp bạn. Tôi có thể giúp gì cho bạn hôm nay?\" },\n",
    "\t{ \"role\": \"user\", \"content\": \"Tìm nhà ở Hà Nội\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"[CALL_TOOL]\" },\n",
    "\t{ \"role\": \"user\", \"content\": \"Bạn là ai\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"Xin chào! Tôi là trợ lý ảo của bạn, được tạo ra để hỗ trợ bạn trong nhiều vấn đề khác nhau.\" },\n",
    "\t{ \"role\": \"user\", \"content\": \"Cho tôi thông tin về chung cư mini ở Hồ Chí Minh\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"[CALL_TOOL]\" }\n",
    "]\n",
    "\n",
    "result = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-72B-Instruct\", \n",
    "\tmessages=messages, \n",
    "\ttemperature=0.1,\n",
    "\tmax_tokens=1024,\n",
    "\ttop_p=0.7,\n",
    "\tstream=False\n",
    ")\n",
    "\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
